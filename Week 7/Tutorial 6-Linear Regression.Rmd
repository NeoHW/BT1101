---
title: 'Tutorial 6: Linear Regression'
author: 'Haowei'
date: 'Due by October 10, 8:00 AM'
output: html_document
---

## Preparation

```{r load-libraries, echo=TRUE, message=FALSE, warning=FALSE}
# load required packages, for general use
library(dplyr)
library(tidyr)
library(ggplot2) # optional. we expect you to know base graphics, but allow ggplot if you find it easier
library(knitr)
library(psych)
```

## Part One: Lab-Session Completion and Discussion

- Dataset required: `WorldBankData.csv`

(Note: This dataset comes from a publically available dataset from The World Bank. https://databank.worldbank.org/source/world-development-indicators.)


First, load in the dataset for this question. There are 8 variables in this real-world dataset, from 258 countries in 2016/2017:

- `Human.Capital.Index`: unitless number that goes from 0 to 1.
- `GDP.per.capita.PPP` in US Dollar. This is GDP per capita, but taking into account the purchasing power of the local currency, by comparing how much it costs to buy a basket of goods (e.g. food) compared to the reference currency (USD). (PPP stands for Purchasing Power Parity)
- `Health.Expenditure.per.capita` in US Dollar.
- `Tertiary.Education.Expenditure.per.student` in US Dollar.
- `Population`.
- `Life.Expectancy.at.birth` in years.
- `Diabetes.Prevalence` in units of % of population ages 20 to 79.
- `Years.of.Compulsory.Education` in years.

Being a data set in real world, there are lots of missing data. Be wary of this!

```{r q1-read-dataset, echo=TRUE}
d1 = read.csv('WorldBankData.csv')
```

### Question 1 

First, let's investigate `Human.Capital.Index`. As noted by Prime Minister Lee in his 2019 National Day Rally, Singapore topped the world on this Human Capital Index in 2018. Let's try to see what are some of the possible variables that correlate with this.


#### Q1a) Start off by plotting `Human.Capital.Index` (on the y-axis) versus `GDP.per.capita.PPP` on the x-axis. What do you notice? What type of relationship exists between the two variables? Is it linear?
```{r q1a, echo=TRUE}
plot(d1$GDP.per.capita.PPP, d1$Human.Capital.Index)
# Using ggplot
ggplot(d1, aes(x=GDP.per.capita.PPP, y=Human.Capital.Index)) + geom_point() + theme_bw()
```
<p style="color:red">
GDP per capita is correlated with Human Capital Index, such that countries with higher GDP per capita also tend to have higher Human Capital Index.  
However the relationship does not seem to be linear.
</p>


#### Q1b) What type of transformation could you apply? Try a few functions that were shown in class: `x^2, x^3, ...`, `exp(x)`, `log10(x)`. Make a plot that shows a linear relationship, and describe what you did.
For fun: add code into your plot to highlight the dot that represents Singapore. 
```{r q1b, echo=TRUE}

# We are actually only using loggdp, rest is to let us visualise
d1$GDP2 = (d1$GDP.per.capita.PPP)^2
d1$GDP3 = (d1$GDP.per.capita.PPP)^3
d1$logeGDP = log(d1$GDP.per.capita.PPP) #NOTE: Log() is the natural Log; log10() is logarithm of base 10

d1$loggdp = log10(d1$GDP.per.capita.PPP)
# To plot the graph using ggplot
ggplot(d1,aes(x=loggdp,y=Human.Capital.Index))+geom_point()+theme_bw()

# Making Singapore a red circle using plot
plot(d1$loggdp, d1$Human.Capital.Index, col = ifelse(d1$Country.Name =="Singapore", "red", "black"))

# Making Singapore a red dot and having labels using ggplot
ggplot(d1,aes(x=loggdp,y=Human.Capital.Index))+geom_point()+theme_bw()+
  geom_point(data=subset(d1,d1$Country.Name=='Singapore'),col='red')+
  geom_text(data=subset(d1,d1$Country.Name=='Singapore'),aes(label=Country.Name),vjust=-1,hjust=1,col='red')+
  ylim(0.2,1.0)
```

<p style="color:red">
We see an exponential trend, similar to an example in the lecture slides. There may be several possible transformations to get a linear trend.
If we apply the base10 logarithm to GDP per capita, we find that there now seems to be a linear relationship between Human Capital Index and log-GDP-per-capita.
Note, natural log also acceptable, but less interpretable. If log10 GDP is 4.0, then we know that GDP is 10^4 or $10,000.
</p>


#### Q1c) Now that you have a plot of a linear relationship, run a linear regression using `lm()`, predicting `Human Capital Index`. Run `summary()` on the `lm` object to produce an output table. Interpret the output of the `lm()`. What do the `b` coefficients mean? (Interpret them "in English" and try to make sense of the numbers, even if they might seem weird at first. How many countries made it into this regression? (What happened to the rest?) Comment on the goodness-of-fit statistics.
```{r q1c, echo=TRUE}

summary(lm(Human.Capital.Index ~ loggdp, d1))

# look into missing data
# d1.less <- d1 %>% filter(is.na(Human.Capital.Index)) %>% 
#   select(c(Country.Name, GDP.per.capita.PPP))
# kable(d1.less)

```
<p style="color:red">
H0: Intercept == 0, H1: Intercept != 0. Since the p-value of the intercept is 3.03e-16 < 0.05, at the 5% level of significance, we reject H0 in favor of H1, and conclude that intercept != 0, hence statistically significant at the 5% level of significance.  
Intercept(b0) value = -0.43264, suggests average Human Capital Index for a country with loggdp = 0 is -0.43 but HCI is between 0 and 1.  
Slope(b1) = 0.246. When log10-GDP of a country increases by 1 unit, we expect to see an average increase of Human Capital Index by 0.246  
<br>
Data  
Data contains 258 countries. Use (nrow(dta_wb))  
101 observations were deleted due to missingness of an imbalance data set.  
Hence, 157 countries were used in the regression analysis.  
<br>
Degrees of freedom  
n-2 = 157-2 = 155 degrees of freedom, there is one independent variable logGDP plus an intercept  
<br>
R-square is 0.746  
Model explains almost 75% of the total variation of Human Capital Index.  
<br>
F-test’s p-value is significant implies that “not all beta1,... are not zero”  
In this case with only one predictor, beta1 is statistically not zero.
</p>


### Question 2 

- Dataset required: `WorldBankData.csv`

Let's look at another set of variables in the same dataset. This time, let's consider `Health.Expenditure.per.capita`, `Diabetes.Prevalence`, and `Life.Expectancy.at.birth`.

#### Q2a) If you had to design a predictive hypothesis with these three variables, what would it be? Which would be your dependent variable, and which would be your independent variables? Justify your answer. (Note, there is no necessarily "right" or "wrong" answer for this question, as is the case in real life, but there are more justifiable answers that you would feel more comfortable putting up to your boss!)


<p style="color:red">
<b>Life.Expectancy.at.birth</b>
<li style="color:red">Yes, it can be used as an outcome variable. We might seek to increase as a goal, especially if that is something of importance to society.</li>
<br>
<b style="color:red">Health.Expenditure.per.capita</b>
<li style="color:red">Health.Expenditure.per.capita is potentially a policy variable that can be controlled by government. That should be a predictor / independent variable for interesting policy.</li>
<li style="color:red">Question: Could changing health expenditure improve the outcome variable, life expectancy?</li>
<br>
<b style="color:red">Diabetes.Prevalence</b>
<li style="color:red">Yes, Diabetes.Prevalence could also be an outcome that one would want to optimize. If it’s just between Diabetes.Prevalence and Health.Expenditure.per.capita, it could be</li>
<li style="color:red">However, if we also have Life.Expectancy.at.birth, it makes more sense if Diabetes.Prevalence predicts Life.Expectancy.at.birth, than the other way around.</li>
</p>



#### Q2b) Plot the bivariate relationships between these three variables. (In other words, plot x-y scatterplots. There are 3 variables, so you'll need 3 scatterplots.) Please also apply the same transformation in (1b) to `Health.Expenditure.per.capita`. Comment on the relationship between the variables.
```{r q2b, echo=TRUE}
# explain shape and apply transformation

## using plot
plot(d1$Life.Expectancy.at.birth, log(d1$Health.Expenditure.per.capita))
plot(d1$Life.Expectancy.at.birth, d1$Diabetes.Prevalence)
plot(log(d1$Health.Expenditure.per.capita), d1$Diabetes.Prevalence)
qnorm(0.05/2)

## using qqplot
#ggplot(d1, aes(x=Life.Expectancy.at.birth, y = log10(Health.Expenditure.per.capita))) + geom_point() + theme_bw()
#ggplot(d1, aes(x=Life.Expectancy.at.birth, y = Diabetes.Prevalence)) + geom_point() + theme_bw()
#ggplot(d1, aes(x=log10(Health.Expenditure.per.capita), y = Diabetes.Prevalence)) + geom_point() + theme_bw()


```

<p style="color:red"></p>



#### Q2c) Run a multiple regression predicting `Life.Expectancy.at.birth` using the other two variables. Interpret the coefficients, spelling out what the numbers mean. Comment on your answers.

```{r q2c, echo=TRUE}
# explain shape and apply transformation
summary(lm(Life.Expectancy.at.birth ~ log10(Health.Expenditure.per.capita) + Diabetes.Prevalence, d1))

```


<p style="color:red">
Significant Predictors: Both log-Health Expenditure and Diabetes prevalence are statistically significant predictors of Life Expectancy.  
Intercept(b0) value = 39.6, suggests average Life Expectancy At Birth for a country with 0 log-Health expenditure and with 0 diabetes is 39.6.  
Slope(b1) = 10.7. When log-Health expenditure of a country increases by 1 unit, we expect to see an average increase of Life Expectancy At Birth by 10.7.  
Slope(b2) = 0.24. When Diabetes Prevalance of a country increases by 1 unit, we expect to see an average increase of Life Expectancy At Birth by 0.24.  
This could be due to external factors not in our model. For example, perhaps countries that are more affluent have access to more sugary foods, and thus may experience higher rates of diabetes. The affluent countries also have access to better healthcare and hence may enjoy longer life expectancies.
</p>


## Part Two: Assignment Submission 

### Tutorial Question 3 (Total 20 points)

For this tutorial question, you are set to explain infidelity in marriage and the likelihood of having an affair using an interesting data set.  

- Dataset required: `data(affairs)` in `wooldridge` package. 
- There are many publicly available data sets to play with in the textbook of `Introduction to Econometrics` by Jeffrey Wooldridge. We'll use those real world data sets (usually random subset of the original data set) quite often in this course. 

```{r q3-prep, echo=TRUE}
# Install the `wooldridge` data package locally if this is your first time to load the package.
# install.packages('wooldridge') 
# Load the library 
library(wooldridge)
# Load the dataset `affairs`
data(affairs)
# Take a quick look at the first 10 rows of data
head(affairs)
d1 <- affairs
```
- The data set `affaris` contains 601 observations of 19 variables on individual's demographic information, self-ratings and event of having and affair. The description of variables is the following:

  + id: identifier
  + male: =1 if male
  + age: in years
  + yrsmarr: years married
  + kids: =1 if have kids
  + relig: 5 = very relig., 4 = somewhat, 3 = slightly, 2 = not at all, 1 = anti
  + educ: years schooling
  + occup: occupation, Hollingshead scale^[Hollingshead scale measures the socialeconomic status with larger number indicating higher social-economic status. [Occupational prestige Wiki](https://en.wikipedia.org/wiki/Occupational_prestige). ]
  + ratemarr: 5 = vry hap marr, 4 = hap than avg, 3 = avg, 2 = smewht unhap, 1 = vry unhap
  + naffairs: number of affairs within last year
  + affair: =1 if had at least one affair
  + vryhap: ratemarr == 5
  + hapavg: ratemarr == 4
  + avgmarr: ratemarr == 3
  + unhap: ratemarr == 2
  + vryrel: relig == 5
  + smerel: relig == 4
  + slghtrel: relig == 3
  + notrel: relig == 2
  
(3a) Firstly, let's look at what contributes to the number of affairs during marriage. People believe that infidelity in marriage is associated with gender, age, years of marriage, if having kids together, income level or social-economic status, if religious, and if happily married. Run a multivariate linear regression model of `naffairs` on `male`, `age`, `yrsmarr`, `kids`,  `occup`, `relig`, and `ratemarr` and report the regression result. (1 point) 

Answer the following questions *directly based on the regression output*:

- Interpret the coefficient of `relig`. Does having being religious affect the number of affairs in marriage? Why or why not? (2 points)
- Interpret the coefficient of `yrsmarr`. Does years of marriage affect the number of affairs in marriage? Why or why not? (2 points)
- What's the marginal effect of `ratemarr` and how do you interpret the coefficient of `ratemarr`? (1 point)

Note: use the original `ratemarr` provided in the data for this question, as a numeric variable. 

```{r q3a, echo=TRUE}
## Change binary int variables to factor variables with labels
#d1$male_fac = factor(d1$male)
#d1$kids_fac = factor(d1$kids)
#summary(lm(naffairs ~ male_fac + age + yrsmarr + kids_fac + occup + relig + ratemarr, d1))
## Looks like there is no difference when using factor or binary numeric variable

summary(lm(naffairs ~ male + age + yrsmarr + kids + occup + relig + ratemarr, d1))
# check for normality needed?
```

<p style="color:darkred">
Coefficient of `relig` = -0.47642. Every unit increase of how religious a person is decreases the average number of affairs during marriage by 0.47642 given all other predictors constant.  
The p-value=2.25e-05 is very small,(< 0.05), thus we have sufficient evidence to reject the null hypothesis that the intercept is 0 and conclude that the slope parameter is statistically significant at the 5% level of confidence.  
<br>
Coefficient of `yrsmarr` = 0.16947. Every unit increase number of years married increases the average number of affairs during marriage by 0.16947 given all other predictors constant.   
The p-value=4.43e-05 is very small,(< 0.05), thus we have sufficient evidence to reject the null hypothesis that the intercept is 0 and conclude that the slope parameter is statistically significant at the 5% level of confidence.  
<br>
Coefficient of `ratemarr` = -0.71544. Every unit increase of how happy a person is in the marriage decreases the average number of affairs during marriage by 0.71544 given all other predictors constant.   
The p-value=2.98e-09 is very small,(< 0.05), thus we have sufficient evidence to reject the null hypothesis that the intercept is 0 and conclude that the slope parameter is statistically significant at the 5% level of confidence.  
</p>


(3b) Observe that `ratemarr` is an example of likert rating which is a categorical variable.^[It is actually slightly different from *nominal categorical variable* we saw in class such as `weather` which takes three possible values of `sunny`, `cloudy`, `rainy`. We call `ratemarr` an **ordinal categorical variable** since there is an intrinsic ordering in the values of `ratemarr`, i.e. `vry hap`(5) > `hap than avg`(4) > `avg`(3) > `smewht unhap`(2) > `vry unhap`(1) but the difference between adjacent values has no meaning. However, we'll still use `factormarr` as nominal categorical variable instead of ordinal categorical one, as we code `order=FALSE` as shown in the codechunk] In previous question (3a), we actually treat `ratemarr` as an integer-valued continuous variable where difference of two nearby values means something. In order to fix this issue, let's use `level()` function in R to convert a numeric variable `ratemarr` into an a categorical variable or factor variable in R.

Now re-run and report the linear regression model in previous question with `ratemarr` and `relig` replaced by `factormarr` and `factorelig`, respectively. (1 point) 

- What is the marginal effect on number of affairs when rating jumps from `vry unhap` to `smewht unhap`; and from `hap than avg` to `vry hap`? (2 points) 
- What's the difference of marginal effect of marriage happiness rating on number of affairs between an integer-valued `ratemarr`  and factor variable `factormarr`? (1 point)

```{r q3b-prep, echo=TRUE}
# use level function to manually recode `ratemarr` into factor variable.
d1$factormarr = factor(affairs$ratemarr, labels = c('vry unhap', 'smewht unhap', 'avg', 'hap than avg', 'vry hap'), order = FALSE)
# similarly, `relig` should also be recoded. 
d1$factorrelig = factor(affairs$relig, labels = c('anti', 'not at all', 'slightly', 'somewhat', 'vry relig'), order = FALSE)

summary(lm(naffairs ~ male + age + yrsmarr + kids + occup + factorrelig + factormarr, d1))


# Note:
# When one includes a categorical variable of k-level, i.e. factor in R, R will automatically generate k−1 dummies in the regression model, leaving out one reference level. If such categorical variable has an order, generated dummies follow the natural order and the reference level is usually the lowest level. We can use relevel() function in R to set the reference level.
```


<p style="color:darkred">
From `vry unhap` to `smewht unhap`:  
The marginal effect of marriage rating from `vry unhap` to `smewht unhap` is 0.27810.  
However, p-value=0.746200 > 0.05, thus we do not have sufficient evidence to reject the null hypothesis that the coefficient is 0. Therefore, the coefficient is statistically insignificant at the 5% level of confidence.  
<br>
From `hap than avg` to `vry hap`:  
The marginal effect of marriage rating from `hap than avg` to `vry hap` results in a -2.58116-(-2.24427) = -0.33689.  
`hap than avg` p-value=0.005514 < 0.05, thus we have sufficient evidence to reject the null hypothesis that the intercept is 0 and conclude that the slope parameter is statistically significant at the 5% level of confidence.  
`vry hap` p-value=0.001472 < 0.05, thus we have sufficient evidence to reject the null hypothesis that the intercept is 0 and conclude that the slope parameter is statistically significant at the 5% level of confidence.  
<br>
Difference of marginal effect of marriage happiness rating on number of affairs between an integer-valued `ratemarr`  and factor variable `factormarr`:  
In the case of this model, for integer-valued `ratemarr`, jumping from adjacent levels shares exactly the same marginal effect on number of affairs.  
For factor variable `factormarr`, jumping from adjacent levels have separate marginal effect.  
</p>


(3c) It might be interesting to see if there is any inverse U-shaped (marginal) relationship between years of marriage and infidelity in marriage. Fit a multivariate linear regression of `affair` on `male`, `age`, `yrsmarr`, `yrsmarrsq`, `kids`,  `occup`, `factorelig`, and `factormarr` (1 point) , where `yrsmarrsq` is the square of `yrsmarr`.

- Interpret the coefficient before `male`. (2 points)
- What's the marginal effect of years of marriage of having an affair? Write out the formula for this marginal effect. Compute the marginal effect when `yrsmarr = 7`? (2 points)
- Based on the regression output, is there any evidence in the data supporting such inverse U-shaped relationship between years of marriage and number of affairs in marriage? (1 point)
```{r q3c-prep, echo=TRUE}
# `yrsmarrsq` is the square of `yrsmarr`
d1$yrsmarrsq = d1$yrsmarr^2

# Fitting multivariate linear regression 
# To check if infidelity in marriage, use variable `affair` where affairs=1 means at least one affair
fit_a<-lm(naffairs ~ male + age + yrsmarr + yrsmarrsq + kids + occup + factorrelig + factormarr, d1)
summary(fit_a)
```

<p style="color:darkred">
Coefficient of `male` = 0.065418. If the person is a male, the number of affairs during marriage increases by 0.065418 on average given all other predictors constant.    
However, p-value=0.824414(> 0.05), we cannot reject the null hypothesis that this slope parameter is = 0, i.e., the coefficient is not significantly different from zero.  
<br>
Marginal effect of years of marriage of having an affair is 0.289678 - 2 x 0.007020 x yrsmarr.
When yrsmarr = 7, the marginal effect = 0.289678 - 2(0.007020(7)) = 0.191398.
<br>
yrsmarrsq is statistically insignificant with p-value larger than the conventional cutoffs. The data shows little evidence that there exists such non-linear relationship between years in marriage and log-odds of having an affair.
</p>


(3d) Using your fitted linear regression model in (3c), predict the number of affairs in marriage for a very religious 56 year-old father who has a prestigious job (i.e. `occup = 6`) and is very happily married for 22 years. (3 points) 

```{r q3d, echo=TRUE}
newPerson = data.frame(male = 1, age = 56, yrsmarr = 22, yrsmarrsq = 22^2, kids = 1, factorrelig = "vry relig", occup = 6, factormarr = "vry hap")
predict(fit_a, newdata = newPerson)
```

<p style="color:darkred">
The number of affairs in marriage for a very religious 56 year-old father who has a prestigious job (i.e. `occup = 6`) and is very happily married for 22 years is 0.5891839.  
</p>


(3e) Successfully debug Rmarkdown and produce an HTML for submission. (1 point)
